{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lima Buendía"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de datos y creación de datasets limpios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obejtivo\n",
    "La lectura de datos se realiza desde un bucket de s3-\n",
    " \n",
    "De manera general, se tienen cuatro fuentes de datos de redes sociales -tres de redes sociales y una de encabezados de noticias.\n",
    "+ Meta Cloud\n",
    "+ Twitter\n",
    "+ FacebookPages\n",
    "+ FacebookGroup\n",
    "\n",
    "Y dos más de datos oficiales: \n",
    "+ Secretariado Ejecutivo del Sistema Nacional de Seguridad Pública \n",
    "+ INEGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga de librerías\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos las librerías de dotenv\n",
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el ambiente\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id = os.getenv(\"aws_access_key_id\")\n",
    "aws_secret_access_key = os.getenv(\"aws_secret_access_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparacion de conexiones \n",
    "client = boto3.client('s3',\n",
    "    aws_access_key_id = aws_access_key_id,\n",
    "    aws_secret_access_key = aws_secret_access_key,\n",
    "    region_name = 'us-east-1'\n",
    ")\n",
    "    \n",
    "# Creating the high level object oriented interface\n",
    "resource = boto3.resource('s3',\n",
    "    aws_access_key_id = aws_access_key_id,\n",
    "    aws_secret_access_key = aws_secret_access_key,\n",
    "    region_name = 'us-east-1'\n",
    ")\n",
    "\n",
    "session = boto3.Session(aws_access_key_id=aws_access_key_id,\n",
    "                        aws_secret_access_key=aws_secret_access_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parámetros\n",
    "s3_res = session.resource('s3')\n",
    "csv_buffer = StringIO()\n",
    "bucket_name = 'lima-buendia'\n",
    "\n",
    "# Llaves\n",
    "#metacloud = \n",
    "m1 = 'raw/Mediacloud_data_1ene2018a31may2022.csv'\n",
    "m2 = 'raw/Mediacloud_data_1jul2020a31jul2020.csv'\n",
    "m3 = 'raw/Mediacloud_data_1oct2020a31dic2020.csv'\n",
    "m4 = 'raw/Mediacloud_conteo_1oct2021a30nov2021.csv'\n",
    "m5 = 'raw/FBgroups Feminicidios 1ene2017a31may2022.csv'\n",
    "m6 = 'raw/FBpages Feminicidios 1ene2017a31dic2019.csv'\n",
    "m7 = 'raw/FBpages Feminicidios 1ene2020a31may2022.csv'\n",
    "m8 = 'raw/conjunto_de_datos_defunciones_generales_2017.CSV'\n",
    "m9 = 'raw/conjunto_de_datos_defunciones_registradas_2018.csv'\n",
    "m10 = 'raw/conjunto_de_datos_defunciones_registradas_2019.CSV'\n",
    "m11 = 'raw/conjunto_de_datos_defunciones_registradas_2020.csv'\n",
    "m12 = 'raw/catalogos_2017/decatcausa.csv'\n",
    "m13 = 'raw/catalogos_2018/causa_defuncion.csv'\n",
    "m14 = 'raw/catalogos_2019/decatcausa.CSV'\n",
    "m15 = 'raw/catalogos_2020/causa_defuncion.CSV'\n",
    "m16 = 'raw/TW_positivos_negativos.csv'\n",
    "\n",
    "twitter = 'raw/TW_data_1ene2017a31may2022.csv'\n",
    "secretariado = 'raw/Estatal-V¡ctimas-2015-2022_may2022.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion de objetos\n",
    "objm1 = client.get_object(Bucket = bucket_name, Key = m1)\n",
    "objm2 = client.get_object(Bucket = bucket_name, Key = m2)\n",
    "objm3 = client.get_object(Bucket = bucket_name, Key = m3)\n",
    "objm4 = client.get_object(Bucket = bucket_name, Key = m4)\n",
    "objm5 = client.get_object(Bucket = bucket_name, Key = m5)\n",
    "objm6 = client.get_object(Bucket = bucket_name, Key = m6)\n",
    "objm7 = client.get_object(Bucket = bucket_name, Key = m7)\n",
    "objm8 = client.get_object(Bucket = bucket_name, Key = m8)\n",
    "objm9 = client.get_object(Bucket = bucket_name, Key = m9)\n",
    "objm10 = client.get_object(Bucket = bucket_name, Key = m10)\n",
    "objm11 = client.get_object(Bucket = bucket_name, Key = m11)\n",
    "objm12 = client.get_object(Bucket = bucket_name, Key = m12)\n",
    "body12 = objm12['Body']\n",
    "csv_string12 = body12.read().decode('latin')\n",
    "objm13 = client.get_object(Bucket = bucket_name, Key = m13)\n",
    "body13 = objm13['Body']\n",
    "csv_string13 = body13.read().decode('latin')\n",
    "objm14 = client.get_object(Bucket = bucket_name, Key = m14)\n",
    "body14 = objm14['Body']\n",
    "csv_string14 = body14.read().decode('latin')\n",
    "objm15 = client.get_object(Bucket = bucket_name, Key = m15)\n",
    "body15 = objm15['Body']\n",
    "csv_string15 = body15.read().decode('latin')\n",
    "objm16 = client.get_object(Bucket = bucket_name, Key = m16)\n",
    "\n",
    "\n",
    "objt1 = client.get_object(Bucket = bucket_name, Key = twitter)\n",
    "obje = client.get_object(Bucket = bucket_name,  Key = secretariado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lectura de datos de S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mediacloud\n",
    "df_m1 = pd.read_csv(objm1['Body'])\n",
    "df_m2 = pd.read_csv(objm2['Body'])\n",
    "df_m3 = pd.read_csv(objm3['Body'])\n",
    "df_m4 = pd.read_csv(objm4['Body'])\n",
    "\n",
    "#Facebook groups\n",
    "df_m5 = pd.read_csv(objm5['Body'])\n",
    "\n",
    "#Facebook pages\n",
    "df_m6 = pd.read_csv(objm6['Body'])\n",
    "df_m7 = pd.read_csv(objm7['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defunciones\n",
    "df_m8 = pd.read_csv(objm8['Body'])\n",
    "df_m9 = pd.read_csv(objm9['Body'])\n",
    "df_m10 = pd.read_csv(objm10['Body'])\n",
    "df_m11 = pd.read_csv(objm11['Body'])\n",
    "\n",
    "#catalogos y bitacoras\n",
    "df_m12 = pd.read_csv(StringIO(csv_string12))\n",
    "df_m13 = pd.read_csv(StringIO(csv_string13))\n",
    "df_m14 = pd.read_csv(StringIO(csv_string14))\n",
    "df_m15 = pd.read_csv(StringIO(csv_string15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter comentarios positivos y negativos\n",
    "df_m16 = pd.read_csv(objm16['Body']) \n",
    "        \n",
    "#twitter\n",
    "df2 = pd.read_csv(objt1['Body'])\n",
    "\n",
    "#secretariado. estadísticas estatales\n",
    "estatal =pd.read_excel(io.BytesIO(obje['Body'].read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= list(stopwords.words('spanish'))\n",
    "stop_words.extend((\"https\",\"co\", \"si\",  \"tras\", \"años\",\"https\", \"t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciones \n",
    "\n",
    "# Función para obtener la fecha en mes y año de Facebook Pages y Groups\n",
    "def funcion_fecha_facebook(df):\n",
    "    df['Post Created'] = pd.to_datetime(df['Post Created'])\n",
    "    df['year'], df['month'], df['day'], df['hour'], \\\n",
    "    df['minute'], df['second'] = df['Post Created'].dt.year,\\\n",
    "    df['Post Created'].dt.month, df['Post Created'].dt.day, df['Post Created'].dt.hour,\\\n",
    "    df['Post Created'].dt.minute, df['Post Created'].dt.second\n",
    "    df['date']= df['Post Created'].dt.date\n",
    "    df['YM'] = df['Post Created'].dt.to_period('M')\n",
    "\n",
    "#limpieza y separacion por tokens\n",
    "def limpiar_tokenizar(texto):\n",
    "    nuevo_texto = texto.lower()\n",
    "    nuevo_texto = re.sub(\"\\\\s+\", ' ', nuevo_texto)\n",
    "    regex = '[\\\\!\\\\\"\\\\#\\\\{\\'+}\\\\$\\\\%\\\\&\\\\\\'\\\\(\\\\)\\\\*\\\\+\\\\,\\\\-\\\\.\\\\/\\\\:\\\\;\\\\<\\\\=\\\\>\\\\?\\\\@\\\\[\\\\\\\\\\\\]\\\\^_\\\\`\\\\{\\\\|\\\\}\\\\~\\\\“\\\\´\\\\‘\\\\”]'\n",
    "    nuevo_texto = re.sub(regex , ' ', nuevo_texto) \n",
    "    nuevo_texto = nuevo_texto.strip()\n",
    "    nuevo_texto = nuevo_texto.split(sep = ' ')\n",
    "    nuevo_texto = [token for token in nuevo_texto if not token in stop_words]\n",
    "    nuevo_texto = [token for token in nuevo_texto if len(token) > 2]\n",
    "    return(nuevo_texto)\n",
    "\n",
    "# Limpieza sin eliminar números ni emojis\n",
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFKD', s)\n",
    "      if unicodedata.category(c)!='Mn')\n",
    "\n",
    "def limpia(s):\n",
    "    s = unicode_to_ascii(s)\n",
    "    s = s.upper().strip()\n",
    "    regex = '[\\\\!\\\\\"\\\\$\\\\%\\\\&\\\\\\'\\\\(\\\\)\\\\*\\\\+\\\\,\\\\-\\\\.\\\\/\\\\:\\\\;\\\\<\\\\=\\\\>\\\\?\\\\@\\\\[\\\\\\\\\\\\]\\\\^_\\\\`\\\\{\\\\|\\\\}\\\\~]'\n",
    "    s = re.sub(regex, ' ', s) \n",
    "    s = re.sub(\"\\\\s+\", ' ', s)\n",
    "    s = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', s, flags=re.MULTILINE)\n",
    "    s = ' '.join(cad for cad in  s.split(' ') if cad !='')\n",
    "    return s.lower()\n",
    "\n",
    "def limpia1(s):\n",
    "    s = s.replace('https', '').replace('www', '').replace('youtube', '').replace(' com ', '').replace('http', '').replace('facebook', '')  \n",
    "    s = re.sub(\"\\\\s+\", ' ', s)\n",
    "    return s\n",
    "\n",
    "# Nos quedamos con mujeres y homicidio\n",
    "def funcion(df):\n",
    "    df = df[df['sexo'] == 2]\n",
    "    df = df[df['presunto'] == 2]\n",
    "    return df\n",
    "\n",
    "\n",
    "# Obtenemos la fecha de mes y año para los datos de defunción de INEGI\n",
    "def funcion_fecha_def(df):\n",
    "    df = df.reset_index()\n",
    "    df['anio_regis'] = df['anio_regis'].astype('str')\n",
    "    df['mes_regis'] = df['mes_regis'].astype('str')\n",
    "    df['time'] = df['anio_regis'] + '-' + df['mes_regis']\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df['YM'] = df['time'].map(lambda x: x.strftime('%Y-%m'))\n",
    "    df = pd.concat([df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura, limpieza y transformación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mediacloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de dataset de mediacloud\n",
    "df = pd.concat([df_m1, df_m2, df_m3])\n",
    "\n",
    "#Transformación del tipo de fecha\n",
    "df['publish_date'] = pd.to_datetime(df['publish_date'], format=\"%Y-%m-%d\")\n",
    "\n",
    "#Creación de componentes de fecha\n",
    "df['year'], df['month'], df['day'] = df['publish_date'].dt.year,\\\n",
    "df['publish_date'].dt.month, df['publish_date'].dt.day\n",
    "\n",
    "\n",
    "df['date']= df['publish_date'].dt.date\n",
    "df['YM']=df['publish_date'].dt.to_period('M')\n",
    "\n",
    "df['title_tokenizado'] = df['title'].apply(lambda x: limpiar_tokenizar(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(csv_buffer)\n",
    "s3_res.Object(bucket_name, 'clean/cleaned_mediacloud.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para octubre y noviembre de 2021, no se tienen los encabezados de Mediacloud. Únicamente los conteos diarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m4['date'] = pd.to_datetime(df_m4['date'], format=\"%Y-%m-%d\")\n",
    "\n",
    "#Creación de componentes de fecha\n",
    "df_m4['year'], df_m4['month'], df_m4['day'] = df_m4['date'].dt.year,\\\n",
    "df_m4['date'].dt.month, df_m4['date'].dt.day\n",
    "df_m4['YM']=df_m4['date'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m4.to_csv(csv_buffer)\n",
    "s3_res.Object(bucket_name, 'clean/cleaned_metacloud_oct_nov.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos estatales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estatal1 = estatal[(estatal.Sexo=='Mujer') & (estatal.Año>2015)]\n",
    "\n",
    "estatal1 = estatal1[['Año', 'Tipo de delito', 'Enero', 'Febrero', 'Marzo', 'Abril', 'Mayo', 'Junio', 'Julio', 'Agosto', 'Septiembre', 'Octubre', 'Noviembre', 'Diciembre']]\n",
    "\n",
    "estatal1_melt = pd.melt(estatal1, id_vars=['Año', 'Tipo de delito'], value_vars=[ 'Enero', 'Febrero', 'Marzo', 'Abril', 'Mayo', 'Junio', 'Julio', 'Agosto', 'Septiembre', 'Octubre', 'Noviembre', 'Diciembre'])\n",
    "\n",
    "estatal1_melt['mes'] = np.where(estatal1_melt['variable']=='Enero', '01',\n",
    "                                np.where(estatal1_melt['variable']=='Febrero', '02',\n",
    "                                         np.where(estatal1_melt['variable']=='Marzo', '03',\n",
    "                                                  np.where(estatal1_melt['variable']=='Abril', '04', \n",
    "                                                           np.where(estatal1_melt['variable']=='Mayo', '05',\n",
    "                                                                    np.where(estatal1_melt['variable']=='Junio', '06',\n",
    "                                                                             np.where(estatal1_melt['variable']=='Julio', '07',\n",
    "                                                                                      np.where(estatal1_melt['variable']=='Agosto', '08',\n",
    "                                                                                               np.where(estatal1_melt['variable']=='Septiembre', '09',\n",
    "                                                                                                        np.where(estatal1_melt['variable']=='Octubre', '10',\n",
    "                                                                                                                 np.where(estatal1_melt['variable']=='Noviembre', '11', \n",
    "                                                                                                                          '12')))))))))))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "estatal1_melt['Año'] = estatal1_melt['Año'].astype('str')\n",
    "estatal1_melt['mes'] = estatal1_melt['mes'].astype('str')\n",
    "estatal1_melt['YM'] = estatal1_melt['Año'] + '-' + estatal1_melt['mes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_agregados = pd.DataFrame(estatal1_melt.groupby(['YM', 'Tipo de delito']).agg({'value':lambda x: x.dropna().sum()}).rename(columns={'value':'delitos'})).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_agregados.to_csv(csv_buffer)\n",
    "s3_res.Object(bucket_name, 'clean/agregados_nacionales.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformación del timestamp\n",
    "df2['created_at']=pd.to_datetime(df2['created_at'])\n",
    "\n",
    "#Creación de componentes de fecha\n",
    "df2['year'], df2['month'], df2['day'], df2['hour'], \\\n",
    "df2['minute'], df2['second'] = df2['created_at'].dt.year,\\\n",
    "df2['created_at'].dt.month, df2['created_at'].dt.day, df2['created_at'].dt.hour,\\\n",
    "df2['created_at'].dt.minute, df2['created_at'].dt.second\n",
    "\n",
    "df2['date']= df2['created_at'].dt.date\n",
    "df2['YM']=df2['created_at'].dt.to_period('M')\n",
    "\n",
    "df2['text_tokenizado'] = df2['text'].apply(lambda x: limpiar_tokenizar(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(csv_buffer)\n",
    "s3_res.Object(bucket_name, 'clean/cleaned_twitter.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Facebook Groups & Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcion_fecha_facebook(df_m5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m7 = pd.concat([df_m6, df_m7]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcion_fecha_facebook(df_m7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m5['Message'] = df_m5['Message'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m5['Clean_Message'] = df_m5['Message'].map(limpia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m5['Clean_Message'] = df_m5['Clean_Message'].map(limpia1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m7['Message'] = df_m7['Message'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m7['Clean_Message'] = df_m7['Message'].map(limpia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m7['Clean_Message'] = df_m7['Clean_Message'].map(limpia1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m5.to_csv(csv_buffer)\n",
    "s3_res.Object(bucket_name, 'clean/df_FBgroups_clean.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m7.to_csv(csv_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_res.Object(bucket_name, 'clean/df_FBpages_clean.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defunciones INEGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m8 = funcion(df_m8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m9 = funcion(df_m9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m10 = funcion(df_m10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m11 = funcion(df_m11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos las claves de la causa de defunción\n",
    "df_m12 = df_m12.set_index('CVE').T.to_dict('list')\n",
    "df_m13 = df_m13.set_index('CVE').T.to_dict('list')\n",
    "df_m14 = df_m14.set_index('cve').T.to_dict('list')\n",
    "df_m15 = df_m15.set_index('cve').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m8['causa_def'] = df_m8['causa_def'].map(df_m12) \n",
    "df_m9['causa_def'] = df_m9['causa_def'].map(df_m13)\n",
    "df_m10['causa_def'] = df_m10['causa_def'].map(df_m14)\n",
    "df_m11['causa_def'] = df_m11['causa_def'].map(df_m15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m8 = funcion_fecha_def(df_m8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m9 = funcion_fecha_def(df_m9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m10 = funcion_fecha_def(df_m10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m11 = funcion_fecha_def(df_m11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m8.to_csv(csv_buffer)\n",
    "s3_res.Object(bucket_name, 'clean/clean_feminicidios_2017.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m9.to_csv(csv_buffer)\n",
    "s3_res.Object(bucket_name, 'clean/clean_feminicidios_2018.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m10.to_csv(csv_buffer)\n",
    "s3_res.Object(bucket_name, 'clean/clean_feminicidios_2019.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m11.to_csv(csv_buffer)\n",
    "s3_res.Object(bucket_name, 'clean/clean_feminicidios_2020.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweets positivos y negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el total de tweets \n",
    "df_m16['Total_tweets'] = df_m16['tuits_negativos'] + df_m16['tuits_positivos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el año y el mes\n",
    "df_m16['fecha'] = pd.to_datetime(df_m16['fecha'])\n",
    "df_m16['YM'] = df_m16['fecha'].map(lambda x: x.strftime('%Y-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m16.to_csv(csv_buffer)\n",
    "s3_res.Object(bucket_name, 'clean/tweets_pos_neg.csv').put(Body=csv_buffer.getvalue())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
